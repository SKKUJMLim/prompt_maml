{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "g5PRKeDDuvFr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5sDE8DI3ua1g"
      },
      "outputs": [],
      "source": [
        "# 간단한 모델 정의\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.layer1 = nn.Linear(10, 5)  # Freeze 대상\n",
        "        self.layer2 = nn.Linear(5, 1)  # 학습 대상\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n",
        "\n",
        "# 모델 복사 (두 방법을 독립적으로 실험하기 위해)\n",
        "model1 = SimpleModel()  # requires_grad=False\n",
        "model2 = copy.deepcopy(model1)  # learning_rate=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Optimizer 설정\n",
        "optimizer2 = optim.SGD([\n",
        "    {'params': model2.layer1.parameters(), 'lr': 0.0},  # layer1 Freeze\n",
        "    {'params': model2.layer2.parameters(), 'lr': 0.1}  # 학습\n",
        "])\n",
        "\n",
        "# 1. requires_grad=False 실험\n",
        "for param in model1.layer1.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 입력 데이터와 타깃 생성\n",
        "x = torch.randn(8, 10)  # 입력 데이터\n",
        "y = torch.randn(8, 1)   # 타깃 데이터"
      ],
      "metadata": {
        "id": "cIwg4xR7ujHw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "output1 = model1(x)\n",
        "loss1 = criterion(output1, y)\n",
        "\n",
        "output2 = model2(x)\n",
        "loss2 = criterion(output2, y)\n",
        "\n",
        "# Backward Pass\n",
        "loss1.backward()\n",
        "loss2.backward()\n",
        "\n",
        "# Optimizer Step\n",
        "# (model1은 requires_grad=False로 인해 Optimizer 필요 없음)\n",
        "optimizer2.step()\n",
        "\n",
        "# Compare layer1 weights\n",
        "print(\"\\nlayer2.weight values comparison:\")\n",
        "print(\"model1 (requires_grad=False):\", model1.layer1.weight.data)\n",
        "print(\"model2 (learning_rate=0):\", model2.layer1.weight.data)\n",
        "print(\"Are weights equal?\", torch.allclose(model1.layer1.weight.data, model2.layer1.weight.data))\n",
        "\n",
        "\n",
        "# Compare layer2 weights\n",
        "print(\"\\nlayer2.weight values comparison:\")\n",
        "print(\"model1 (requires_grad=False):\", model1.layer2.weight.data)\n",
        "print(\"model2 (learning_rate=0):\", model2.layer2.weight.data)\n",
        "print(\"Are weights equal?\", torch.allclose(model1.layer2.weight.data, model2.layer2.weight.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAEYFOXfu7zA",
        "outputId": "f24f4b51-73d1-4551-9dc9-8c010d1ab0ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "layer2.weight values comparison:\n",
            "model1 (requires_grad=False): tensor([[-0.2314, -0.2362,  0.2633,  0.3005,  0.2951,  0.3033,  0.1839, -0.1985,\n",
            "         -0.2011, -0.0437],\n",
            "        [-0.0956, -0.2457, -0.1331, -0.3159, -0.0498,  0.0175,  0.0210,  0.1499,\n",
            "         -0.0426,  0.2129],\n",
            "        [-0.3009, -0.0329,  0.1318,  0.3105,  0.1225,  0.1839, -0.2842,  0.0626,\n",
            "          0.0298, -0.0483],\n",
            "        [-0.2429, -0.1088,  0.1813,  0.2302,  0.0484,  0.0344, -0.2778,  0.1923,\n",
            "          0.2885, -0.1139],\n",
            "        [-0.2684,  0.1971, -0.2305, -0.2347, -0.0004,  0.0748,  0.1602, -0.1460,\n",
            "         -0.0861, -0.3100]])\n",
            "model2 (learning_rate=0): tensor([[-0.2314, -0.2362,  0.2633,  0.3005,  0.2951,  0.3033,  0.1839, -0.1985,\n",
            "         -0.2011, -0.0437],\n",
            "        [-0.0956, -0.2457, -0.1331, -0.3159, -0.0498,  0.0175,  0.0210,  0.1499,\n",
            "         -0.0426,  0.2129],\n",
            "        [-0.3009, -0.0329,  0.1318,  0.3105,  0.1225,  0.1839, -0.2842,  0.0626,\n",
            "          0.0298, -0.0483],\n",
            "        [-0.2429, -0.1088,  0.1813,  0.2302,  0.0484,  0.0344, -0.2778,  0.1923,\n",
            "          0.2885, -0.1139],\n",
            "        [-0.2684,  0.1971, -0.2305, -0.2347, -0.0004,  0.0748,  0.1602, -0.1460,\n",
            "         -0.0861, -0.3100]])\n",
            "Are weights equal? True\n",
            "\n",
            "layer2.weight values comparison:\n",
            "model1 (requires_grad=False): tensor([[ 0.1795,  0.0604, -0.0496, -0.0752, -0.3023]])\n",
            "model2 (learning_rate=0): tensor([[ 0.1559,  0.1137, -0.0980, -0.1404, -0.1574]])\n",
            "Are weights equal? False\n"
          ]
        }
      ]
    }
  ]
}